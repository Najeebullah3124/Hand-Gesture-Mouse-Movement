# ğŸ–ï¸ Hand Gesture Mouse Control ğŸ–±ï¸

This project uses **computer vision** to control the mouse pointer and perform clicks through **hand gestures**. It leverages the `mediapipe` library for hand detection, `pyautogui` for mouse control, and `opencv` for video capture and processing. ğŸ–¥ï¸ğŸ’»ğŸ‘†

## ğŸš€ Requirements

To run this project, you need to have the following Python libraries installed:

- `opencv-python` ğŸ“·
- `mediapipe` ğŸ¤–
- `pyautogui` ğŸ–±ï¸
- `numpy` â—

You can install the required libraries using `pip`:

```bash
pip install opencv-python mediapipe pyautogui numpy

âš™ï¸ How It Works
Hand Tracking: The program uses mediapipe to detect hand landmarks âœ‹. Specifically, it tracks the index finger (landmark 8) and thumb (landmark 4).
Mouse Movement: The position of the index finger (landmark 8) is mapped to the screen coordinates to move the mouse pointer ğŸ–±ï¸.
Mouse Click: When the index finger and thumb come close (within a defined distance), a mouse click is simulated using pyautogui ğŸ‘†ğŸ–±ï¸.
Real-time Feedback: The camera feed is displayed in a window with detected hand landmarks and fingertip positions marked with green circles ğŸ”µ.
ğŸƒâ€â™‚ï¸ Usage
Run the Python script ğŸ.
The camera feed will open, and the program will start detecting hand gestures ğŸ‘‹.
Move your index finger to control the mouse pointer ğŸ–±ï¸.
Bring your thumb and index finger together to perform a click ğŸ‘†ğŸ‘Œ.
